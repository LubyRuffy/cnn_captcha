# -*- coding: utf-8 -*-
from __future__ import division, print_function, absolute_import

import tflearn
from tflearn.layers.core import input_data, dropout, fully_connected
from tflearn.layers.conv import conv_2d, max_pool_2d
from tflearn.layers.normalization import local_response_normalization
from tflearn.layers.estimator import regression

# Data loading and preprocessing
import tflearn.datasets.mnist as mnist
#X, Y, testX, testY = mnist.load_data(one_hot=True)
#X = X.reshape([-1, 28, 28, 1])
#testX = testX.reshape([-1, 28, 28, 1])


#mnist = input_data.read_data_sets("MNIST_data/", one_hot=True)
#print("Download Done!")

lst = []
for line in open('code1.txt', 'r'):
    lst.append(line.strip())

sample_cnt = len(lst)

W = 60
H = 16
C = 3
X_dim = W*H*C
Y_dim = 4

X = np.zeros( (sample_cnt, W*H*C) )
#Y = np.zeros( (sample_cnt, 4) )
Y = np.zeros( (sample_cnt, 10) )


for sam_idx in range(len(lst)):
    line = lst[sam_idx]
    v = string.split(line, ' ')
    v_len = len(v)
    img0 = cv2.imread(v[0])
    if img0 != None:
        img = cv2.resize(img0, (W, H), fx=1, fy=1, interpolation=cv2.INTER_LINEAR)
        img1 = img.reshape( (-1,) )
        img1 = img1/255.0
        X[sam_idx] = img1
        tmp = np.zeros( (10) )

        '''
        print int(v[1])
        print int(v[2])
        print int(v[3])
        print int(v[4])
        xx = raw_input('pause:')
        print tmp.shape
        '''

        tmp[int(v[1])] = 1.0
        Y[sam_idx, :] = tmp
        #print Y[0]
        #xx = raw_input('pause:')
        #Y[sam_idx][0] = int(v[1])
        #Y[sam_idx][1] = int(v[2])
        #Y[sam_idx][2] = int(v[3])
        #Y[sam_idx][3] = int(v[4])

print '123321'
print X.shape
print Y.shape
xx = raw_input('pause:')

'''
testid = 123
line = lst[testid]
v = string.split(line, ' ')
img = cv2.imread(v[0])
cv2.imshow("img", img)
cv2.waitKey(0)
print v
print X[0]
print Y[0]
xx = raw_input('pause:')
'''
print("Load Data finished!")


# Building convolutional network
network = input_data(shape=[None, W, H, C], name='input')
network = conv_2d(network, 32, 3, activation='relu', regularizer="L2")
network = max_pool_2d(network, 2)
network = local_response_normalization(network)
network = conv_2d(network, 64, 3, activation='relu', regularizer="L2")
network = max_pool_2d(network, 2)
network = local_response_normalization(network)
network = fully_connected(network, 128, activation='tanh')
network = dropout(network, 0.8)
network = fully_connected(network, 256, activation='tanh')
network = dropout(network, 0.8)
network = fully_connected(network, 10, activation='softmax')
network = regression(network, optimizer='adam', learning_rate=0.01,
                     loss='categorical_crossentropy', name='target')

# Training
model = tflearn.DNN(network, tensorboard_verbose=0)
model.fit({'input': X}, {'target': Y}, n_epoch=20,
           validation_set=({'input': testX}, {'target': testY}),
           snapshot_step=100, show_metric=True, run_id='convnet_mnist')
