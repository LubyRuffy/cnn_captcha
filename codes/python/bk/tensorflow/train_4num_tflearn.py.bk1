import sys,os
import cv2
import numpy as np
import tensorflow as tf
import string
#from tensorflow.examples.tutorials.mnist import input_data
import tensorflow.examples.tutorials.mnist.input_data as mnist_input_data

import tflearn
from tflearn.layers.core import input_data, dropout, fully_connected
from tflearn.layers.conv import conv_2d, max_pool_2d
from tflearn.layers.normalization import local_response_normalization
from tflearn.layers.estimator import regression
from tflearn.layers.merge_ops import merge
from tflearn.data_preprocessing import ImagePreprocessing
from tflearn.data_augmentation import ImageAugmentation


lst = []
for line in open('code1.txt', 'r'):
    lst.append(line.strip())

sample_cnt = len(lst)

W = 64
#W = 224
H = 16
#H = 56
C = 1
X_dim = W*H*C
Y_dim = 40

X0 = np.zeros( (sample_cnt, X_dim) )
Y0 = np.zeros( (sample_cnt, Y_dim) )


for sam_idx in range(len(lst)):
    line = lst[sam_idx]
    v = string.split(line, ' ')
    v_len = len(v)
    img0 = cv2.imread(v[0])
    if img0 != None:
        img00 = cv2.cvtColor(img0, cv2.COLOR_BGR2GRAY)
        img = cv2.resize(img00, (W, H), fx=1, fy=1, interpolation=cv2.INTER_LINEAR)
        img1 = img.reshape( (-1,) )
        img1 = img1/255.0
        X0[sam_idx] = img1
        tmp = np.zeros( (40) )
        tmp[0 +int(v[1])] = 1.0
        tmp[10+int(v[2])] = 1.0
        tmp[20+int(v[3])] = 1.0
        tmp[30+int(v[4])] = 1.0
        Y0[sam_idx, :] = tmp[0: Y_dim]
        '''
        if sam_idx == 123:
            print int(v[1])
            print int(v[2])
            print int(v[3])
            print int(v[4])
            print tmp
            xx = raw_input('pause:')
        '''

# train mnist for test
'''W = 28
H = 28
C = 1
mnist_data = mnist_input_data.read_data_sets("MNIST_data/", one_hot=True)
print type(mnist_data)
(X_data, Y_data) = (mnist_data.train.images, mnist_data.train.labels)

print X_data.shape
print Y_data.shape
X0 = X_data
Y0 = Y_data
'''

print X0.shape
print Y0.shape

X = X0.reshape( (-1, W, H, C) )
Y = Y0

print X.shape
print Y.shape


train_cnt = int(sample_cnt*0.9)
trainX = X[0:train_cnt, :]
trainY = Y[0:train_cnt]
testX  = X[train_cnt:, :]
testY  = Y[train_cnt:]


#xx = raw_input('pause:')
'''
print "check"
testid = 123
line = lst[testid]
v = string.split(line, ' ')
img = cv2.imread(v[0])
cv2.imshow("img", img)
print v
print X[0]
print Y[0]
cv2.waitKey(0)
xx = raw_input('pause:')
'''
print("Load Data finished!")



def get_net():
    # Building convolutional network

    # Real-time data preprocessing
    img_prep = ImagePreprocessing()
    img_prep.add_featurewise_zero_center()
    img_prep.add_featurewise_stdnorm()

    # Real-time data augmentation
    img_aug = ImageAugmentation()
    img_aug.add_random_flip_leftright()
    img_aug.add_random_rotation(max_angle=25.)

    # Convolutional network building
    #network = input_data(shape=[None, 32, 32, 3], data_preprocessing=img_prep, data_augmentation=img_aug)

    network = input_data(shape=[None, W, H, C], data_preprocessing=img_prep, data_augmentation=img_aug, name='input')

    network = conv_2d(network, 32, 3, activation='relu', regularizer="L2")
    #network = max_pool_2d(network, 2)
    network = local_response_normalization(network)

    network = conv_2d(network, 32, 3, activation='relu', regularizer="L2")
    #network = max_pool_2d(network, 2)
    network = local_response_normalization(network)

    network = conv_2d(network,64, 3, activation='relu', regularizer="L2")
    network = max_pool_2d(network, 2)
    network = local_response_normalization(network)

    network = conv_2d(network, 64, 3, activation='relu', regularizer="L2")
    #network = max_pool_2d(network, 2)
    network = local_response_normalization(network)

    network = conv_2d(network, 128, 3, activation='relu', regularizer="L2")
    network = max_pool_2d(network, 2)
    network = local_response_normalization(network)

    network = conv_2d(network, 64, 3, activation='relu', regularizer="L2")
    network = max_pool_2d(network, 2)
    network = local_response_normalization(network)

    network = fully_connected(network, 1024, activation='tanh')
    network = dropout(network, 0.8)

    network = fully_connected(network, 1024, activation='tanh')
    network = dropout(network, 0.8)


    fc11 = fully_connected(network, 256, activation='relu', regularizer='L2', weight_decay=0.001)
    fc11 = dropout(fc11, 0.5)
    fc12 = fully_connected(network, 256, activation='relu', regularizer='L2', weight_decay=0.001)
    fc12 = dropout(fc12, 0.5)
    fc13 = fully_connected(network, 256, activation='relu', regularizer='L2', weight_decay=0.001)
    fc13 = dropout(fc13, 0.5)
    fc14 = fully_connected(network, 246, activation='relu', regularizer='L2', weight_decay=0.001)
    fc14 = dropout(fc14, 0.5)

    fc21 = fully_connected(network, 10, activation='softmax')
    fc22 = fully_connected(network, 10, activation='softmax')
    fc23 = fully_connected(network, 10, activation='softmax')
    fc24 = fully_connected(network, 10, activation='softmax')

    fc = merge( [fc1, fc2, fc3, fc4], mode = 'concat', axis = 1)

    network = fully_connected(fc, Y_dim, activation='softmax')

    #network = regression(network, optimizer='adam', learning_rate=0.01,
    #                     loss='categorical_crossentropy', name='target')
    network = regression(network, optimizer='SGD', learning_rate=0.1,
                         loss='categorical_crossentropy', name='target')

    return network




def get_mnist_net():
    # Building convolutional network
    network = input_data(shape=[None, W, H, C], name='input')
    network = conv_2d(network, 32, 3, activation='relu', regularizer="L2")
    network = max_pool_2d(network, 2)
    network = local_response_normalization(network)
    network = conv_2d(network, 64, 3, activation='relu', regularizer="L2")
    network = max_pool_2d(network, 2)
    network = local_response_normalization(network)
    network = fully_connected(network, 128, activation='tanh')
    network = dropout(network, 0.8)
    network = fully_connected(network, 256, activation='tanh')
    network = dropout(network, 0.8)
    network = fully_connected(network, Y_dim, activation='softmax')
    network = regression(network, optimizer='adam', learning_rate=0.01,
                         loss='categorical_crossentropy', name='target')
    #network = regression(network, optimizer='adam', learning_rate=0.01,
    #                     loss='softmax', name='target')

    return network



#network = get_mnist_net()
network = get_net()


# Training
model = tflearn.DNN(network, tensorboard_verbose=1, checkpoint_path='./model_ckpt/model',
                            max_checkpoints=10)
model.fit({'input': trainX}, {'target': trainY}, n_epoch=20,
           validation_set=({'input': testX}, {'target': testY}),
           snapshot_step=100, show_metric=True, run_id='convnet_mnist')


'''
save_path="./model4/model.ckpt"
saver.save(sess,save_path)

# accuacy on test
#print("test accuracy %g"%(accuracy.eval(feed_dict={x: test_X, y_: test_Y, keep_prob: 1.0})))
print("test accuracy %g" % sess.run(accuracy, feed_dict={x: test_X, y_: test_Y, keep_prob: 1.0}))

print "truth y"
print test_Y[0:10]
pre_y = sess.run(y_conv, feed_dict={x: test_X, y_: test_Y, keep_prob: 1.0})
print pre_y[0:10]
'''
